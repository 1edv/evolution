{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import aux\n",
    "from aux import *\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "##Clear Memory \n",
    "tf.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "##\n",
    "\n",
    "\n",
    "NUM_GPU = len(get_available_gpus())\n",
    "if(NUM_GPU>0) :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "#tpu_grpc_url = TPUClusterResolver(tpu=['edv-tpu2'] , zone='us-central1-a').get_master()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Load the Model in a separate graph here as there are two models in this figure.\n",
    "fitness_function_graph = tf.Graph()\n",
    "with fitness_function_graph.as_default():\n",
    "    model_conditions='Glu'\n",
    "    model, scaler,batch_size = load_model(model_conditions)\n",
    "    \n",
    "plotting_alpha=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "<li>Y_pred contains the predictions\n",
    "<li>X is the format of one-hot encoded input expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hq_testdata(filename) :\n",
    "\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        d = list(reader)\n",
    "\n",
    "    sequences = [di[0] for di in d]\n",
    "\n",
    "    for i in tqdm(range(0,len(sequences))) : \n",
    "        if (len(sequences[i]) > 110) :\n",
    "            sequences[i] = sequences[i][-110:]\n",
    "        if (len(sequences[i]) < 110) : \n",
    "            while (len(sequences[i]) < 110) :\n",
    "                sequences[i] = 'N'+sequences[i]\n",
    "\n",
    "\n",
    "\n",
    "    A_onehot = np.array([1,0,0,0] ,  dtype=np.bool)\n",
    "    C_onehot = np.array([0,1,0,0] ,  dtype=np.bool)\n",
    "    G_onehot = np.array([0,0,1,0] ,  dtype=np.bool)\n",
    "    T_onehot = np.array([0,0,0,1] ,  dtype=np.bool)\n",
    "    N_onehot = np.array([0,0,0,0] ,  dtype=np.bool)\n",
    "\n",
    "    mapper = {'A':A_onehot,'C':C_onehot,'G':G_onehot,'T':T_onehot,'N':N_onehot}\n",
    "    worddim = len(mapper['A'])\n",
    "    seqdata = np.asarray(sequences)\n",
    "    seqdata_transformed = seq2feature(seqdata)\n",
    "    print(seqdata_transformed.shape)\n",
    "\n",
    "\n",
    "    expressions = [di[1] for di in d]\n",
    "    expdata = np.asarray(expressions)\n",
    "    expdata = expdata.astype('float')  \n",
    "\n",
    "    return np.squeeze(seqdata_transformed),expdata\n",
    "\n",
    "X,Y = read_hq_testdata(os.path.join('..','..','data','Glu','HQ_testdata.txt'))\n",
    "Y = [float(x) for x in Y]\n",
    "Y_pred = evaluate_model(X, model, scaler, batch_size , fitness_function_graph)\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(Y_pred,Y)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Measured')\n",
    "#print('MSE',sklearn.metrics.mean_squared_error(Y_pred,Y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model \n",
    "<li> Here, we have the measured expression values Y corresponding to the sequences X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(4,4), dpi= 200, facecolor='w', edgecolor='k')\n",
    "\n",
    "sns.regplot(Y_pred,Y , s=5 , linewidth=0.25)\n",
    "plt.title(scipy.stats.spearmanr(Y_pred,Y)[0])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Measured')\n",
    "ax = plt.gca()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "ax.autoscale(enable=True, axis='x', tight=True)\n",
    "ax.autoscale(enable=True, axis='y', tight=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seq]",
   "language": "python",
   "name": "conda-env-seq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
