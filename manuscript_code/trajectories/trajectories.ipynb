{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 18:25:54.157451 46970166161024 deprecation_wrapper.py:119] From ../aux.py:30: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ahg/regevdata/users/edv/software/anaconda3/envs/me/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.3 when using version 0.20.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "W0922 18:26:03.278317 46970166161024 deprecation.py:506] From /ahg/regevdata/users/edv/software/anaconda3/envs/me/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0922 18:26:05.008341 46970166161024 deprecation.py:506] From /ahg/regevdata/users/edv/software/anaconda3/envs/me/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0922 18:26:05.010810 46970166161024 deprecation.py:506] From /ahg/regevdata/users/edv/software/anaconda3/envs/me/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0922 18:26:05.691225 46970166161024 deprecation_wrapper.py:119] From ../aux.py:1643: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from aux import *\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "##Clear Memory \n",
    "tf.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "##\n",
    "\n",
    "\n",
    "if 1: \n",
    "    NUM_GPU = len(get_available_gpus())\n",
    "    if(NUM_GPU>0) :\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "\n",
    "    print(tf.__version__)\n",
    "    print(keras.__version__)\n",
    "    #tpu_grpc_url = TPUClusterResolver(tpu=['edv-tpu2'] , zone='us-central1-a').get_master()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Load the Model \n",
    "    model_conditions ='Glu' # Glu\n",
    "    model_conditions_original ='Glu' # Glu\n",
    "\n",
    "\n",
    "    model , scaler, batch_size = load_model(model_conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Specific Functions and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "### Generate all possible single mutations in population : population_next \n",
    "\n",
    "def population_mutator( population_current , args) :\n",
    "    population_current = population_remove_flank(population_current)\n",
    "    population_next = []  \n",
    "    for i in range(len(population_current)) :         \n",
    "        for j in range(args['sequence_length']) : \n",
    "        #First create three copies of the same individual, one for each possible mutation at the basepair.\n",
    "            population_next.append(list(population_current[i]))\n",
    "            population_next.append(list(population_current[i]))\n",
    "            population_next.append(list(population_current[i]))\n",
    "            \n",
    "            if (population_current[i][j] == 'A') :\n",
    "                population_next[3*(args['sequence_length']*i + j) ][j] = 'C'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 1][j] = 'G'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 2][j] = 'T'\n",
    "                \n",
    "            elif (population_current[i][j] == 'C') :\n",
    "                population_next[3*(args['sequence_length']*i + j)][j] = 'A'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 1][j] = 'G'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 2][j] = 'T'\n",
    "            \n",
    "            elif (population_current[i][j] == 'G') :\n",
    "                population_next[3*(args['sequence_length']*i + j)][j] = 'C'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 1][j] = 'A'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 2][j] = 'T'\n",
    "                \n",
    "            elif (population_current[i][j] == 'T') :\n",
    "                population_next[3*(args['sequence_length']*i + j)][j] = 'C'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 1][j] = 'G'\n",
    "                population_next[3*(args['sequence_length']*i + j) + 2][j] = 'A'\n",
    "             \n",
    "        \n",
    "    population_next= population_add_flank(population_next)        \n",
    "    return list(population_next)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "### Find the single bp mutation that has highest expression \n",
    "def maximize_next_generation(population_current, population_current_fitness): \n",
    "    population_next_all = population_mutator(list(population_current) , args)\n",
    "    population_next_all_predictions = evaluate_model(list(population_next_all),model,scaler,batch_size)\n",
    "    \n",
    "    population_next_max_seq = list(population_current)  \n",
    "    population_next_max_seq_fitness = list(population_current_fitness)\n",
    "    for i in tqdm(range(len(population_current))) :  \n",
    "        max_score = -np.inf\n",
    "        for j in range(3*args['sequence_length']) : \n",
    "            if (population_next_all_predictions[3*args['sequence_length']*i + j] > max_score) :\n",
    "                population_next_max_seq[i] = population_next_all[3*args['sequence_length']*i + j]\n",
    "                population_next_max_seq_fitness[i] = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "                max_score = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "  \n",
    "    return list(population_next_max_seq) , list(population_next_max_seq_fitness)\n",
    "    #print population_next_all_predictions\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "### INTRA FUNCTION NAMES ARE WRONG, VARIABLE IS RIGHT THOUGH , Find the single bp mutation that has least expression \n",
    "def minimize_next_generation(population_current, population_current_fitness): \n",
    "    population_next_all = population_mutator(list(population_current) , args)\n",
    "    population_next_all_predictions = evaluate_model(list(population_next_all),model,scaler,batch_size)\n",
    "    population_next_min_seq = list(population_current)  \n",
    "    population_next_min_seq_fitness = list(population_current_fitness)\n",
    "    for i in range(len(population_current)) :  \n",
    "        min_score = np.inf\n",
    "        for j in range(3*args['sequence_length']) : \n",
    "            if (population_next_all_predictions[3*args['sequence_length']*i + j] < min_score) :\n",
    "                population_next_min_seq[i] = population_next_all[3*args['sequence_length']*i + j]\n",
    "                population_next_min_seq_fitness[i] = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "                min_score = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "  \n",
    "    return list(population_next_min_seq) , list(population_next_min_seq_fitness)\n",
    "    #print population_next_all_predictions\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "### Select Randomly from the 240 possible mutations\n",
    "def neutral_next_generation(population_current, population_current_fitness): \n",
    "    population_next_all = population_mutator(list(population_current) , args)\n",
    "    population_next_neutral_seq = list(population_current)  \n",
    "    for i in tqdm(range(len(population_current))) : \n",
    "        j = np.random.choice(3*args['sequence_length'])    ### Pick a random but different neighbour     \n",
    "        population_next_neutral_seq[i] = population_next_all[3*args['sequence_length']*i + j]\n",
    "\n",
    "    population_next_neutral_seq_fitness = evaluate_model(list(population_next_neutral_seq),model,scaler,batch_size)\n",
    "\n",
    "\n",
    "    return list(population_next_neutral_seq) , list(population_next_neutral_seq_fitness)\n",
    "    #print population_next_all_predictions\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "### Plotting Functions\n",
    "\n",
    "def _statsmodels_univariate_kde(data, kernel, bw, gridsize, cut, clip,\n",
    "                                cumulative=False):\n",
    "    \"\"\"Compute a univariate kernel density estimate using statsmodels.\"\"\"\n",
    "    fft = kernel == \"gau\"\n",
    "    kde = smnp.KDEUnivariate(data)\n",
    "    kde.fit(kernel, bw, fft, gridsize=gridsize, cut=cut, clip=clip)\n",
    "    if cumulative:\n",
    "        grid, y = kde.support, kde.cdf\n",
    "    else:\n",
    "        grid, y = kde.support, kde.density\n",
    "    return grid, y\n",
    "\n",
    "\n",
    "def _scipy_univariate_kde(data, bw, gridsize, cut, clip):\n",
    "    \"\"\"Compute a univariate kernel density estimate using scipy.\"\"\"\n",
    "    try:\n",
    "        kde = stats.gaussian_kde(data, bw_method=bw)\n",
    "    except TypeError:\n",
    "        kde = stats.gaussian_kde(data)\n",
    "        if bw != \"scott\":  # scipy default\n",
    "            msg = (\"Ignoring bandwidth choice, \"\n",
    "                   \"please upgrade scipy to use a different bandwidth.\")\n",
    "            warnings.warn(msg, UserWarning)\n",
    "    if isinstance(bw, string_types):\n",
    "        bw = \"scotts\" if bw == \"scott\" else bw\n",
    "        bw = getattr(kde, \"%s_factor\" % bw)() * np.std(data)\n",
    "    grid = _kde_support(data, bw, gridsize, cut, clip)\n",
    "    y = kde(grid)\n",
    "    return grid, y\n",
    "\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "#########################################################################################################\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Starting sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Native Sequences\n",
    "native_sequences_df = pd.read_csv(os.path.join('..','..','data','native_sequences_only','nativeChunks.2.uniq.txt') , header=None)\n",
    "\n",
    "\n",
    "#pd.read_csv(os.path.join('..','..','data','native_sequences_only','native_sequences.txt') , sep='\\t', index_col=0, header=None)\n",
    "native_sequences_list = population_add_flank(list(native_sequences_df[0]))#list(native_sequences_df[1])\n",
    "\n",
    "\n",
    "args  = { 'population_size' : len(native_sequences_list ), \n",
    "         'sequence_length' : 80 , 'nucleotide_frequency' :[0.25,0.25,0.25,0.25] , 'randomizer' : np.random } \n",
    "\n",
    "\n",
    "random = 1 ### If you wanna show the neutral trajectory on random sequences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Random Sequences\n",
    "if 0 :\n",
    "    if random==1 :\n",
    "        random_sequences_list = population_generator(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectories under Random Genetic Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1: \n",
    "    if random==1  :\n",
    "        ### Generate Data\n",
    "        generation_neutral_seq = []\n",
    "        generation_neutral_seq_fitness = []\n",
    "\n",
    "        population = random_sequences_list #idt_seqs#native_mutate_sequences###population_generator( args ) ## replace with new sequence list\n",
    "\n",
    "        generation_neutral_seq.append(list(population)) #population to maximize , generation_max_seq[0]\n",
    "        generation_neutral_seq_fitness.append(list(evaluate_model(list(population),model,scaler,batch_size)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        args['num_rounds'] = 40\n",
    "        for i in tqdm(range(args['num_rounds'])) : \n",
    "            population_next_neutral_seq , population_next_neutral_seq_fitness = neutral_next_generation(generation_neutral_seq[i] , generation_neutral_seq_fitness[i])\n",
    "            generation_neutral_seq.append(population_next_neutral_seq)\n",
    "            generation_neutral_seq_fitness.append(population_next_neutral_seq_fitness)\n",
    "\n",
    "\n",
    "        len(generation_neutral_seq_fitness)\n",
    "\n",
    "\n",
    "        neutral_array = np.transpose(np.asarray(generation_neutral_seq_fitness))\n",
    "        neutral_dataframe = pd.DataFrame(data = neutral_array , index = generation_neutral_seq[0])\n",
    "\n",
    "\n",
    "\n",
    "        neutral_dataframe.to_csv(model_conditions+'neutral_evolution_random.tsv' ,sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else :\n",
    "        ### Generate Data\n",
    "        generation_neutral_seq = []\n",
    "        generation_neutral_seq_fitness = []\n",
    "\n",
    "        population = native_sequences_list #idt_seqs#native_mutate_sequences###population_generator( args ) ## replace with new sequence list\n",
    "\n",
    "        generation_neutral_seq.append(list(population)) #population to maximize , generation_max_seq[0]\n",
    "        generation_neutral_seq_fitness.append(list(evaluate_model(list(population),model,scaler,batch_size)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        args['num_rounds'] = 40\n",
    "        for i in tqdm(range(args['num_rounds'])) : \n",
    "            population_next_neutral_seq , population_next_neutral_seq_fitness = neutral_next_generation(generation_neutral_seq[i] , generation_neutral_seq_fitness[i])\n",
    "            generation_neutral_seq.append(population_next_neutral_seq)\n",
    "            generation_neutral_seq_fitness.append(population_next_neutral_seq_fitness)\n",
    "\n",
    "\n",
    "        len(generation_neutral_seq_fitness)\n",
    "\n",
    "\n",
    "        neutral_array = np.transpose(np.asarray(generation_neutral_seq_fitness))\n",
    "        neutral_dataframe = pd.DataFrame(data = neutral_array , index = generation_neutral_seq[0])\n",
    "\n",
    "\n",
    "\n",
    "        neutral_dataframe.to_csv(model_conditions+'neutral_evolution_native.tsv' ,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectories under SSWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = \"native\"\n",
    "if 0 : \n",
    "    model , scaler, batch_size = load_model(model_conditions_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1 :\n",
    "    #neutral_dataframe = pd.read_csv('neutral_evolution.tsv' , sep='\\t' , index_col=0)\n",
    "    if r_n == \"native\" : \n",
    "        population = native_sequences_list#neutral_dataframe.index.values[0:10000] #idt_seqs####population_generator( args ) ## replace with new sequence list\n",
    "    elif r_n == \"random\" : \n",
    "        population = neutral_dataframe.index.values[0:10000] #idt_seqs####population_generator( args ) ## replace with new sequence list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    generation_max_seq = []\n",
    "    generation_max_seq_fitness = []\n",
    "\n",
    "    generation_min_seq = []\n",
    "    generation_min_seq_fitness = []\n",
    "\n",
    "\n",
    "    generation_max_seq.append(list(population)) #population to maximize , generation_max_seq[0]\n",
    "    generation_max_seq_fitness.append(list(evaluate_model(list(population),model,scaler,batch_size)))\n",
    "\n",
    "    generation_min_seq.append(list(population))\n",
    "    generation_min_seq_fitness.append(list(generation_max_seq_fitness[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    args['num_rounds'] = 10\n",
    "    for i in tqdm(range(args['num_rounds'])) : \n",
    "        population_next_max_seq , population_next_max_seq_fitness = maximize_next_generation(generation_max_seq[i] , generation_max_seq_fitness[i])\n",
    "        generation_max_seq.append(population_next_max_seq)\n",
    "        generation_max_seq_fitness.append(population_next_max_seq_fitness)\n",
    "\n",
    "        population_next_min_seq , population_next_min_seq_fitness = minimize_next_generation(generation_min_seq[i] , generation_min_seq_fitness[i])\n",
    "        generation_min_seq.append(population_next_min_seq)\n",
    "        generation_min_seq_fitness.append(population_next_min_seq_fitness)\n",
    "\n",
    "\n",
    "\n",
    "    len(generation_max_seq_fitness)\n",
    "\n",
    "\n",
    "    max_array = np.transpose(np.asarray(generation_max_seq_fitness))\n",
    "    max_dataframe = pd.DataFrame(data = max_array , index = generation_max_seq[0])\n",
    "\n",
    "    min_array = np.transpose(np.asarray(generation_min_seq_fitness))\n",
    "    min_dataframe = pd.DataFrame(data = min_array , index = generation_min_seq[0])\n",
    "\n",
    "    max_melt = max_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "    min_melt = min_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "\n",
    "    max_melt['Selection Direction'] = 'max'\n",
    "    min_melt['Selection Direction'] = 'min'\n",
    "\n",
    "    merged_melt = min_melt.append(max_melt)\n",
    "\n",
    "\n",
    "    max_seq_array = np.transpose(np.asarray(generation_max_seq))\n",
    "    max_seq_dataframe = pd.DataFrame(data = max_seq_array , index = generation_max_seq[0])\n",
    "\n",
    "    min_seq_array = np.transpose(np.asarray(generation_min_seq))\n",
    "    min_seq_dataframe = pd.DataFrame(data = min_seq_array , index = generation_min_seq[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save/Load Data Frames \n",
    "if 0: \n",
    "    max_seq_dataframe.to_csv(model_conditions+r_n+'_'+'directed_evolution_max_seq.tsv' ,sep='\\t')\n",
    "    min_seq_dataframe.to_csv(model_conditions+r_n+'_'+'directed_evolution_min_seq.tsv' ,sep='\\t')\n",
    "\n",
    "    max_dataframe.to_csv(model_conditions+r_n+'_'+'directed_evolution_max.tsv' ,sep='\\t')\n",
    "    min_dataframe.to_csv(model_conditions+r_n+'_'+'directed_evolution_min.tsv' ,sep='\\t')\n",
    "\n",
    "else : \n",
    "    max_dataframe = pd.read_csv(model_conditions+r_n+'_'+'directed_evolution_max.tsv' ,sep='\\t' , index_col=0)\n",
    "    min_dataframe = pd.read_csv(model_conditions+r_n+'_'+'directed_evolution_min.tsv' ,sep='\\t', index_col=0)\n",
    "\n",
    "max_melt = max_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "min_melt = min_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "\n",
    "max_melt['Selection Direction'] = 'max'\n",
    "min_melt['Selection Direction'] = 'min'\n",
    "\n",
    "merged_melt = min_melt.append(max_melt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectories for optimizing conflicting expression objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = \"native\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the two models into model1,scaler1 and model2,scaler2\n",
    "\n",
    "model_conditions_original=='SC_Ura'\n",
    "\n",
    "if 0 : \n",
    "    ### Load the other model\n",
    "    if model_conditions_original=='SC_Ura':\n",
    "        model1 , scaler1, batch_size = load_model('SC_Ura')\n",
    "        model2 , scaler2, batch_size = load_model('Glu')\n",
    "\n",
    "    else :\n",
    "        model1 , scaler1, batch_size = load_model('Glu')\n",
    "        model2 , scaler2, batch_size = load_model('SC_Ura')\n",
    "\n",
    "    multiobjective_model = Model([model1.input,model2.input], Concatenate(axis=1)([model1.output,model2.output]))\n",
    "\n",
    "\n",
    "#neutral_dataframe = pd.read_csv('neutral_evolution.tsv' , sep='\\t' , index_col=0)\n",
    "if r_n == \"native\" : \n",
    "    population = native_sequences_list#neutral_dataframe.index.values[0:10000] #idt_seqs####population_generator( args ) ## replace with new sequence list\n",
    "elif r_n == \"random\" : \n",
    "    population = neutral_dataframe.index.values[0:10000] #idt_seqs####population_generator( args ) ## replace with new sequence list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1 :\n",
    "    def evaluate_multiobjective_model(X,multiobjective_model, batch_size) :\n",
    "        X = seq2feature(X)\n",
    "        Y_pred = multiobjective_model.predict( [X,X] , batch_size = batch_size , verbose=1)\n",
    "        return scaler1.inverse_transform(Y_pred[:,0]) , scaler2.inverse_transform(Y_pred[:,1])\n",
    "\n",
    "\n",
    "\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "    ### Find the single bp mutation that has highest expression \n",
    "    def mo_maximize_next_generation(population_current, population_current_fitness): \n",
    "        population_next_all = population_mutator(list(population_current) , args)\n",
    "        model_predicitons = evaluate_multiobjective_model(population_next_all,multiobjective_model,batch_size)\n",
    "        population_next_all_predictions = list(model_predicitons[0] -  model_predicitons[1])\n",
    "\n",
    "        population_next_max_seq = list(population_current)  \n",
    "        population_next_max_seq_fitness = list(population_current_fitness)\n",
    "        for i in tqdm(range(len(population_current))) :  \n",
    "            max_score = -np.inf\n",
    "            for j in range(3*args['sequence_length']) : \n",
    "                if (population_next_all_predictions[3*args['sequence_length']*i + j] > max_score) :\n",
    "                    population_next_max_seq[i] = population_next_all[3*args['sequence_length']*i + j]\n",
    "                    population_next_max_seq_fitness[i] = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "                    max_score = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "\n",
    "        return list(population_next_max_seq) , list(population_next_max_seq_fitness)\n",
    "        #print population_next_all_predictions\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "    ### INTRA FUNCTION NAMES ARE WRONG, VARIABLE IS RIGHT THOUGH , Find the single bp mutation that has least expression \n",
    "    def mo_minimize_next_generation(population_current, population_current_fitness): \n",
    "        population_next_all = population_mutator(list(population_current) , args)\n",
    "        model_predicitons = evaluate_multiobjective_model(population_next_all,multiobjective_model,batch_size)\n",
    "        population_next_all_predictions = list(model_predicitons[0] -  model_predicitons[1])\n",
    "\n",
    "        population_next_min_seq = list(population_current)  \n",
    "        population_next_min_seq_fitness = list(population_current_fitness)\n",
    "        for i in range(len(population_current)) :  \n",
    "            min_score = np.inf\n",
    "            for j in range(3*args['sequence_length']) : \n",
    "                if (population_next_all_predictions[3*args['sequence_length']*i + j] < min_score) :\n",
    "                    population_next_min_seq[i] = population_next_all[3*args['sequence_length']*i + j]\n",
    "                    population_next_min_seq_fitness[i] = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "                    min_score = population_next_all_predictions[3*args['sequence_length']*i + j]\n",
    "\n",
    "        return list(population_next_min_seq) , list(population_next_min_seq_fitness)\n",
    "        #print population_next_all_predictions\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "    #########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    generation_max_seq = []\n",
    "    generation_max_seq_fitness = []\n",
    "\n",
    "    generation_min_seq = []\n",
    "    generation_min_seq_fitness = []\n",
    "\n",
    "\n",
    "    generation_max_seq.append(list(population)) #population to maximize , generation_max_seq[0]\n",
    "    model_predicitons = evaluate_multiobjective_model(population,multiobjective_model,batch_size)    \n",
    "    generation_max_seq_fitness.append(list( model_predicitons[0] -  model_predicitons[1]))\n",
    "\n",
    "    generation_min_seq.append(list(population))\n",
    "    generation_min_seq_fitness.append(list(generation_max_seq_fitness[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    args['num_rounds'] = 10\n",
    "    for i in tqdm(range(args['num_rounds'])) : \n",
    "        population_next_max_seq , population_next_max_seq_fitness = mo_maximize_next_generation(generation_max_seq[i] , generation_max_seq_fitness[i])\n",
    "        generation_max_seq.append(population_next_max_seq)\n",
    "        generation_max_seq_fitness.append(population_next_max_seq_fitness)\n",
    "\n",
    "        population_next_min_seq , population_next_min_seq_fitness = mo_minimize_next_generation(generation_min_seq[i] , generation_min_seq_fitness[i])\n",
    "        generation_min_seq.append(population_next_min_seq)\n",
    "        generation_min_seq_fitness.append(population_next_min_seq_fitness)\n",
    "\n",
    "\n",
    "\n",
    "    len(generation_max_seq_fitness)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    max_array = np.transpose(np.asarray(generation_max_seq_fitness))\n",
    "    max_dataframe = pd.DataFrame(data = max_array , index = generation_max_seq[0])\n",
    "\n",
    "    min_array = np.transpose(np.asarray(generation_min_seq_fitness))\n",
    "    min_dataframe = pd.DataFrame(data = min_array , index = generation_min_seq[0])\n",
    "\n",
    "    max_melt = max_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "    min_melt = min_dataframe.melt(value_name='expression' , var_name='edit_distance')\n",
    "\n",
    "    max_melt['Selection Direction'] = 'max'\n",
    "    min_melt['Selection Direction'] = 'min'\n",
    "\n",
    "    merged_melt = min_melt.append(max_melt)\n",
    "\n",
    "    #max_dataframe.to_csv('multiobjective_directed_evolution_max.tsv' ,sep='\\t')\n",
    "    #min_dataframe.to_csv('multiobjective_directed_evolution_min.tsv' ,sep='\\t')\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_seq_array = np.transpose(np.asarray(generation_max_seq))\n",
    "    max_seq_dataframe = pd.DataFrame(data = max_seq_array , index = generation_max_seq[0])\n",
    "\n",
    "    min_seq_array = np.transpose(np.asarray(generation_min_seq))\n",
    "    min_seq_dataframe = pd.DataFrame(data = min_seq_array , index = generation_min_seq[0])\n",
    "\n",
    "\n",
    "    scura_max_dataframe=copy.deepcopy(max_dataframe)\n",
    "    scura_min_dataframe=copy.deepcopy(min_dataframe)\n",
    "\n",
    "    glu_max_dataframe=copy.deepcopy(max_dataframe)\n",
    "    glu_min_dataframe=copy.deepcopy(min_dataframe)\n",
    "\n",
    "\n",
    "    for i in range(scura_max_dataframe.shape[1]) : \n",
    "        scura_max_dataframe.iloc[:,i] = evaluate_model(max_seq_dataframe.iloc[:,i].values , \n",
    "                                                       model1 , scaler1,batch_size)\n",
    "        scura_min_dataframe.iloc[:,i] = evaluate_model(min_seq_dataframe.iloc[:,i].values , \n",
    "                                                       model1 , scaler1,batch_size)\n",
    "\n",
    "\n",
    "        glu_max_dataframe.iloc[:,i] = evaluate_model(max_seq_dataframe.iloc[:,i].values , \n",
    "                                                       model2 , scaler2,batch_size)\n",
    "        glu_min_dataframe.iloc[:,i] = evaluate_model(min_seq_dataframe.iloc[:,i].values , \n",
    "                                                       model2 , scaler2,batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save all the data to TSV / load it\n",
    "if 1 :\n",
    "    max_seq_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_max_seq.tsv' , sep='\\t')\n",
    "    min_seq_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_min_seq.tsv' , sep='\\t')\n",
    "    scura_max_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_scura_max_dataframe.tsv' , sep='\\t')\n",
    "    scura_min_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_scura_min_dataframe.tsv' , sep='\\t')\n",
    "    glu_max_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_glu_max_dataframe.tsv' , sep='\\t')\n",
    "    glu_min_dataframe.to_csv(r_n+'_'+'multiobjective_directed_evolution_glu_min_dataframe.tsv' , sep='\\t')\n",
    "\n",
    "    \n",
    "\n",
    "if r_n == 'native' : \n",
    "    scura_max_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_scura_max_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "    scura_min_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_scura_min_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "\n",
    "    glu_max_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_glu_max_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "    glu_min_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_glu_min_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "\n",
    "elif r_n == 'random' : \n",
    "    scura_max_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_scura_max_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "    scura_min_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_scura_min_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "\n",
    "    glu_max_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_glu_max_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "    glu_min_dataframe = pd.read_csv(r_n+'_'+'multiobjective_directed_evolution_glu_min_dataframe.tsv' , sep='\\t',index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:me] *",
   "language": "python",
   "name": "conda-env-me-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
