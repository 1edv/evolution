{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conda environment required for running this notebook can be installed and activated by running the following on the command line from within this folder: \n",
    "<code>conda env create -f evolution_env_gpu_only.yml </code>  \\\n",
    "<code>conda activate seq</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import creator, base, tools, algorithms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf, sys, numpy as np, h5py, pandas as pd\n",
    "import copy\n",
    "from os.path import splitext,exists,dirname,join,basename\n",
    "\n",
    "\n",
    "#mapper = {'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],'T':[0,0,0,1],'N':[0,0,0,0]}\n",
    "#worddim = len(mapper['A'])\n",
    "A_onehot = np.array([1,0,0,0] ,  dtype=np.bool)\n",
    "C_onehot = np.array([0,1,0,0] ,  dtype=np.bool)\n",
    "G_onehot = np.array([0,0,1,0] ,  dtype=np.bool)\n",
    "T_onehot = np.array([0,0,0,1] ,  dtype=np.bool)\n",
    "N_onehot = np.array([0,0,0,0] ,  dtype=np.bool)\n",
    "\n",
    "mapper = {'A':A_onehot,'C':C_onehot,'G':G_onehot,'T':T_onehot,'N':N_onehot}\n",
    "worddim = len(mapper['A'])\n",
    "\n",
    "\n",
    "# Function to embed sequences and another one to get reverse complements\n",
    "def seq2feature(data,mapper,worddim):\n",
    "\n",
    "    \n",
    "    transformed = np.zeros([data.shape[0],1,len(data[0]),4] , dtype=np.bool )\n",
    "    for i in range(data.shape[0]) :\n",
    "        for j,k in enumerate(data[i]):\n",
    "            #print j,k\n",
    "            transformed[i,0,j] = mapper[k] \n",
    "            #print mapper[k]\n",
    "    return transformed\n",
    "    \n",
    "def get_rc(A):\n",
    "    A_r = np.flip(A,2)\n",
    "    A = A_r\n",
    "    A_onehot = np.array([1,0,0,0] ,  dtype=np.bool)\n",
    "    C_onehot = np.array([0,1,0,0] ,  dtype=np.bool)\n",
    "    G_onehot = np.array([0,0,1,0] ,  dtype=np.bool)\n",
    "    T_onehot = np.array([0,0,0,1] ,  dtype=np.bool)\n",
    "    N_onehot = np.array([0,0,0,0] ,  dtype=np.bool)\n",
    "\n",
    "    for i in range(A.shape[0]) : \n",
    "        for j in range(A.shape[2]) : \n",
    "            if np.array_equal(A[i][0][j] , A_onehot) :\n",
    "                A[i][0][j] = T_onehot\n",
    "            elif np.array_equal(A[i][0][j] , C_onehot) :\n",
    "                A[i][0][j] = G_onehot\n",
    "            elif np.array_equal(A[i][0][j] , G_onehot) :\n",
    "                A[i][0][j] = C_onehot\n",
    "            elif np.array_equal(A[i][0][j] , T_onehot) :\n",
    "                A[i][0][j] = A_onehot\n",
    "            elif np.array_equal(A[i][0][j] , N_onehot) :\n",
    "                A[i][0][j] = N_onehot\n",
    "\n",
    "                \n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def fitness(population):\n",
    "\n",
    "    population_nn = [];\n",
    "    population_fits = [];\n",
    "    for ind in range(len(population)) :\n",
    "        individual_nn = ''.join(['T','G','C','A','T','T','T','T','T','T','T','C','A','C','A','T','C'] + population[ind] + ['G','G','T','T','A','C','G','G','C','T','G','T','T'] )\n",
    "        population_nn.append(individual_nn)\n",
    "        #population_fits.append((population[ind].count('A'),) )\n",
    "    #return population_fits\n",
    "\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        #sequences = list()\n",
    "        #for individual in range(len(population)) :\n",
    "        #    sequence = (''.join(population[individual]))\n",
    "        #    sequences.append(sequence)\n",
    "        #print sequences\n",
    "        _best_model_file = join('motif_disc','best_model.ckpt')\n",
    "        _best_model_file_hyper = join('motif_disc', 'hyper_search', 'best_model.ckpt')\n",
    "    \n",
    "        #sequences = ['NNNTGCATTTTTTTCACATCGGAATGGTGTTGTCGACCTTGCCTTCATAGTTACTTGATGTTAATGATTGGACATGTTCATCAAACCGGGTCACAGAGGTTACGGCTGTT',  'NTGCATTTTTTTCACATCTCGGCGCTTGTGGGTCGTAGCGCATATTCTGTCTACATGTACCTCTTTAATGGCTAATCACGAGGAACGCGCGAGGTAGGGTTACGGCTGTT']\n",
    "        _teX = seq2feature(np.asarray(population_nn),mapper,worddim)\n",
    "        _teX_rc = get_rc(list(_teX)) \n",
    "        _teY = np.zeros([np.shape(_teX)[0] , 1] , dtype=float)\n",
    "        #print X, Y , X_rc , X\n",
    "        sess = tf.Session()\n",
    "        init=tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        #init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        new_saver = tf.train.import_meta_graph('%s.meta'%_best_model_file)\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('motif_disc'))\n",
    "        graph = tf.get_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "        X = graph.get_tensor_by_name('Placeholder:0')\n",
    "        X_rc = graph.get_tensor_by_name('Placeholder_1:0')\n",
    "        Y = graph.get_tensor_by_name('Placeholder_2:0')\n",
    "\n",
    "        model_cost = graph.get_tensor_by_name('out/model_cost:0')\n",
    "        model_output = graph.get_tensor_by_name('out/model_output:0')\n",
    "        #model_accuracy = graph.get_tensor_by_name('out/model_accuracy:0')\n",
    "\n",
    "        #teX_output, teX_cost, teX_accuracy = sess.run([model_output , model_cost, model_accuracy ], feed_dict={X: _teX, X_rc: _teX_rc ,Y: _teY})\n",
    "\n",
    "        teX_output = sess.run([model_output], feed_dict={X: _teX, X_rc: _teX_rc  ,Y: _teY})\n",
    "        tuple_output = list(tuple((x),) for x in teX_output[0])\n",
    "        \n",
    "        return tuple_output\n",
    "\n",
    "\n",
    "#fits = fitness(offspring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import creator, base, tools, algorithms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf, sys, numpy as np, h5py, pandas as pd\n",
    "import copy\n",
    "from os.path import splitext,exists,dirname,join,basename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args  = {'sequence_length' : 80 , 'nucleotide_frequency' :[0.25,0.25,0.25,0.25] } \n",
    "randomizer=np.random\n",
    "\n",
    "def random_sequence_generator(randomizer,args) :\n",
    "    return randomizer.choice(list('ACGT') , p=args['nucleotide_frequency'] ) \n",
    "\n",
    "\n",
    "def mutation(individual, indpb):\n",
    "\n",
    "    for i in xrange(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            if individual[i]=='A' :\n",
    "                individual[i] = (randomizer.choice(list('CGT') , p=[args['nucleotide_frequency'][1]/(1-args['nucleotide_frequency'][0]) ,args['nucleotide_frequency'][2]/(1-args['nucleotide_frequency'][0]) ,args['nucleotide_frequency'][3]/(1-args['nucleotide_frequency'][0]) ] ) )\n",
    "            elif individual[i]=='C' :\n",
    "                individual[i] = (randomizer.choice(list('AGT') , p=[args['nucleotide_frequency'][0]/(1-args['nucleotide_frequency'][1]) ,args['nucleotide_frequency'][2]/(1-args['nucleotide_frequency'][1]) ,args['nucleotide_frequency'][3]/(1-args['nucleotide_frequency'][1]) ] ) )\n",
    "            elif individual[i]=='G' :\n",
    "                individual[i] = (randomizer.choice(list('CGT') , p=[args['nucleotide_frequency'][2]/(1-args['nucleotide_frequency'][2]) ,args['nucleotide_frequency'][1]/(1-args['nucleotide_frequency'][2]) ,args['nucleotide_frequency'][3]/(1-args['nucleotide_frequency'][2]) ] ) )\n",
    "            elif individual[i]=='T' : \n",
    "                individual[i] = (randomizer.choice(list('CGT') , p=[args['nucleotide_frequency'][0]/(1-args['nucleotide_frequency'][3]) ,args['nucleotide_frequency'][1]/(1-args['nucleotide_frequency'][3]) ,args['nucleotide_frequency'][2]/(1-args['nucleotide_frequency'][3]) ] ) )\n",
    "    return individual,\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list , fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"base\", random_sequence_generator , randomizer , args)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.base, n=args['sequence_length'])\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutation, indpb=0.025)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "population = toolbox.population(n=100000)\n",
    "\n",
    "NGEN=10\n",
    "\n",
    "for gen in tqdm(range(NGEN)):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.1, mutpb=0.1)\n",
    "    fits = toolbox.evaluate(offspring)\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    population = toolbox.select(offspring, k=len(population))\n",
    "    \n",
    "top10 = tools.selBest(population, k=10)\n",
    "\n",
    "print top10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seq]",
   "language": "python",
   "name": "conda-env-seq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
